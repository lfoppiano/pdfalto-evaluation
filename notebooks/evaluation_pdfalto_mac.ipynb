{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PDFAlto versions comparison and evaluation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "9252aa15de011c08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:52:09.432264Z",
     "start_time": "2025-05-06T09:52:09.420305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "def compute_statistics(input_pdfalto_A, input_pdfalto_B):\n",
    "    common_subdirs = extract_common_repositories(input_pdfalto_A, input_pdfalto_B)\n",
    "    print(\"Found the following corpus directories: \", common_subdirs)\n",
    "\n",
    "    documents = {}\n",
    "    for corpus in common_subdirs:\n",
    "        print(corpus)\n",
    "        skipped = []\n",
    "        processed = {}\n",
    "        documents[corpus] = {\n",
    "            'processed': processed,\n",
    "            'skipped': skipped,\n",
    "            'pdfalto_A': input_pdfalto_A,\n",
    "            'pdfalto_B': input_pdfalto_B,\n",
    "            'average': {\n",
    "                'pdfalto_A': 0,\n",
    "                'pdfalto_B': 0,\n",
    "                'diff': 0,\n",
    "                'perc': 0\n",
    "            }\n",
    "        }\n",
    "\n",
    "        for root, dirs, files in tqdm(os.walk(os.path.join(input_pdfalto_A, corpus))):\n",
    "            for file in files:\n",
    "                if not file.endswith(\".txt\"):\n",
    "                    continue\n",
    "\n",
    "                # Find the directory relative to the corpus directory\n",
    "                file_id = os.path.relpath(os.path.join(root, file),\n",
    "                                          os.path.join(input_pdfalto_A, corpus)).replace(\".txt\", \"\")\n",
    "\n",
    "                with open(os.path.join(root, file), \"r\") as f:\n",
    "                    txt_pdfalto_A = f.read()\n",
    "\n",
    "                related_B_file = os.path.join(input_pdfalto_B, corpus, file_id + \".txt\")\n",
    "                if not os.path.exists(related_B_file):\n",
    "                    skipped.append((file_id, related_B_file))\n",
    "                    continue\n",
    "\n",
    "                with open(related_B_file, \"r\") as f:\n",
    "                    txt_pdfalto_B = f.read()\n",
    "\n",
    "                txt_pdfalto_A_spaces = ' '.join(txt_pdfalto_A.split())\n",
    "                txt_pdfalto_B_spaces = ' '.join(txt_pdfalto_B.split())\n",
    "\n",
    "                txt_pdfalto_A_spaces_len = len(txt_pdfalto_A_spaces)\n",
    "                txt_pdfalto_B_spaces_len = len(txt_pdfalto_B_spaces)\n",
    "                diff_chars_spaces = txt_pdfalto_A_spaces_len - txt_pdfalto_B_spaces_len\n",
    "\n",
    "                txt_pdfalto_A_no_spaces = ''.join(txt_pdfalto_A.split())\n",
    "                txt_pdfalto_B_no_spaces = ''.join(txt_pdfalto_B.split())\n",
    "\n",
    "                txt_pdfalto_A_len = len(txt_pdfalto_A_no_spaces)\n",
    "                txt_pdfalto_B_len = len(txt_pdfalto_B_no_spaces)\n",
    "                diff_chars_no_spaces = txt_pdfalto_A_len - txt_pdfalto_B_len\n",
    "\n",
    "                txt_pdfalto_A_token_len = len(txt_pdfalto_A_spaces.split())\n",
    "                txt_pdfalto_B_token_len = len(txt_pdfalto_B_spaces.split())\n",
    "                diff_tokens = txt_pdfalto_A_token_len - txt_pdfalto_B_token_len\n",
    "\n",
    "                # related_grobid_file = related_grobid_file.replace(\"tei.xml\", \"diff.txt\")\n",
    "                # # save files\n",
    "                # with open(related_grobid_file, \"w\") as f:\n",
    "                #     f.write(txt_grobid_spaces)\n",
    "                #     f.write(\"\\n\")\n",
    "                #     f.write(txt_pdfalto_spaces)\n",
    "\n",
    "                processed[file_id] = {\n",
    "                    'pdfalto_A': len(txt_pdfalto_A),\n",
    "                    'pdfalto_A_tokens': txt_pdfalto_A_token_len,\n",
    "                    'pdfalto_B': len(txt_pdfalto_B),\n",
    "                    'pdfalto_B_tokens': txt_pdfalto_B_token_len,\n",
    "                    'stats': {\n",
    "                        'diff_chars_no_spaces': diff_chars_no_spaces,\n",
    "                        'diff_chars_spaces': diff_chars_spaces,\n",
    "                        'diff_tokens': diff_tokens\n",
    "                    }\n",
    "                }\n",
    "        print(f\"Processed documents {len(processed)}\")\n",
    "        print(f\"Skipped documents {len(skipped)}\")\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "def extract_common_repositories(input_pdfalto, input_grobid):\n",
    "    # Find the subdirectories in the input corpora\n",
    "    subdirs_pdfalto = [x for x in os.listdir(input_pdfalto)]\n",
    "    print(f\"Found the following corpus directories for PDFAlto A: {subdirs_pdfalto}\")\n",
    "    subdirs_grobid = [x for x in os.listdir(input_grobid)]\n",
    "    print(f\"Found the following corpus directories for PDFAlto B: {subdirs_grobid}\")\n",
    "    # find the common subdirectories\n",
    "    common_subdirs = [x for x in subdirs_grobid if x in subdirs_pdfalto]\n",
    "    return common_subdirs\n",
    "\n",
    "documents_output = {}\n"
   ],
   "id": "c76832531bd7c98f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparison",
   "id": "5d4cc0c23b3b8445"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:52:27.832548Z",
     "start_time": "2025-05-06T09:52:09.453310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pdfalto_A = \"/Volumes/ExtremePro/sciencialab/dimensions/pdfalto-evaluation/output_pdfalto/mac_arm-0.5\"\n",
    "pdfalto_B = \"/Volumes/ExtremePro/sciencialab/dimensions/pdfalto-evaluation/output_pdfalto/output-pdfalto-macos-8cf749a-250506\"\n",
    "\n",
    "documents_output[\"standard\"] = compute_statistics(pdfalto_A, pdfalto_B)"
   ],
   "id": "5929a39f01ff90fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the following corpus directories for PDFAlto A: ['PLOS_1000', 'eLife_984', 'biorxiv-10k-test-2000', 'PMC_sample_1943']\n",
      "Found the following corpus directories for PDFAlto B: ['PLOS_1000', 'eLife_984', 'biorxiv-10k-test-2000', 'PMC_sample_1943']\n",
      "Found the following corpus directories:  ['PLOS_1000', 'eLife_984', 'biorxiv-10k-test-2000', 'PMC_sample_1943']\n",
      "PLOS_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [00:03, 319.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed documents 1000\n",
      "Skipped documents 0\n",
      "eLife_984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "985it [00:04, 236.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed documents 983\n",
      "Skipped documents 1\n",
      "biorxiv-10k-test-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [00:06, 326.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed documents 2001\n",
      "Skipped documents 0\n",
      "PMC_sample_1943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1944it [00:04, 395.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed documents 1942\n",
      "Skipped documents 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:52:27.868892Z",
     "start_time": "2025-05-06T09:52:27.858403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_averages(documents_):\n",
    "    for process_type, process in documents_.items():\n",
    "        for corpus, documents in process.items():\n",
    "            total_pdfalto_A = sum([d['pdfalto_A'] for d in documents['processed'].values()])\n",
    "            total_pdfalto_B = sum([d['pdfalto_B'] for d in documents['processed'].values()])\n",
    "            total_diff_chars_no_spaces = sum([d['stats']['diff_chars_no_spaces'] for d in documents['processed'].values()])\n",
    "            total_diff_chars_spaces = sum([d['stats']['diff_chars_spaces'] for d in documents['processed'].values()])\n",
    "            matching_documents_chars_no_spaces = sum([d['stats']['diff_chars_no_spaces'] == 0 for d in documents['processed'].values()])\n",
    "            matching_documents_chars_spaces = sum([d['stats']['diff_chars_spaces'] == 0 for d in documents['processed'].values()])\n",
    "            total_diff_tokens = sum([d['stats']['diff_tokens'] for d in documents['processed'].values()])\n",
    "            matching_documents_tokens = sum([d['stats']['diff_tokens'] == 0 for d in documents['processed'].values()])\n",
    "\n",
    "            documents['average']['pdfalto_A'] = total_pdfalto_A / len(documents['processed'])\n",
    "            documents['average']['pdfalto_B'] = total_pdfalto_B / len(documents['processed'])\n",
    "            documents['average']['diff_char_no_spaces'] = total_diff_chars_no_spaces / len(documents['processed'])\n",
    "            documents['average']['diff_char_spaces'] = total_diff_chars_spaces / len(documents['processed'])\n",
    "            documents['average']['diff_tokens'] = total_diff_tokens / len(documents['processed'])\n",
    "            documents['average']['matching_documents_chars_spaces'] = matching_documents_chars_spaces\n",
    "            documents['average']['matching_documents_chars_no_spaces'] = matching_documents_chars_no_spaces\n",
    "            documents['average']['matching_documents_tokens'] = matching_documents_tokens\n",
    "\n",
    "    return documents_\n",
    "\n",
    "\n",
    "documents_output_with_average = compute_averages(documents_output)"
   ],
   "id": "27c3e979c72d58b1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Results",
   "id": "92922999340648a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Matching documents\n",
   "id": "5018e40e17213ba4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:52:28.454289Z",
     "start_time": "2025-05-06T09:52:27.892867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns = [\"Chars/Tokens\"]\n",
    "aggregated_data = []\n",
    "for process_type, process in documents_output_with_average.items():\n",
    "    process_data = [\"Chars (no spaces)\"]\n",
    "    for corpus, documents in process.items():\n",
    "        if corpus not in columns:\n",
    "            columns.append(corpus)\n",
    "        process_data.append(documents['average']['matching_documents_chars_no_spaces'])\n",
    "    aggregated_data.append(process_data)\n",
    "    process_data = [\"Chars (spaces)\"]\n",
    "    for corpus, documents in process.items():\n",
    "        if corpus not in columns:\n",
    "            columns.append(corpus)\n",
    "        process_data.append(documents['average']['matching_documents_chars_spaces'])\n",
    "    aggregated_data.append(process_data)\n",
    "    process_data = [\"Tokens\"]\n",
    "    for corpus, documents in process.items():\n",
    "        process_data.append(documents['average']['matching_documents_tokens'])\n",
    "    aggregated_data.append(process_data)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(aggregated_data, columns=columns)"
   ],
   "id": "e30d2f3d89607614",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Chars/Tokens  PLOS_1000  eLife_984  biorxiv-10k-test-2000  \\\n",
       "0  Chars (no spaces)       1000        971                   1985   \n",
       "1     Chars (spaces)       1000        971                   1964   \n",
       "2             Tokens       1000        974                   1967   \n",
       "\n",
       "   PMC_sample_1943  \n",
       "0             1936  \n",
       "1             1937  \n",
       "2             1938  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chars/Tokens</th>\n",
       "      <th>PLOS_1000</th>\n",
       "      <th>eLife_984</th>\n",
       "      <th>biorxiv-10k-test-2000</th>\n",
       "      <th>PMC_sample_1943</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chars (no spaces)</td>\n",
       "      <td>1000</td>\n",
       "      <td>971</td>\n",
       "      <td>1985</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chars (spaces)</td>\n",
       "      <td>1000</td>\n",
       "      <td>971</td>\n",
       "      <td>1964</td>\n",
       "      <td>1937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tokens</td>\n",
       "      <td>1000</td>\n",
       "      <td>974</td>\n",
       "      <td>1967</td>\n",
       "      <td>1938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Average difference",
   "id": "75865c148e8fb4f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:52:28.502287Z",
     "start_time": "2025-05-06T09:52:28.492584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns = [\"Process type\"]\n",
    "aggregated_data = []\n",
    "for process_type, process in documents_output_with_average.items():\n",
    "    process_data = [process_type]\n",
    "    for corpus, documents in process.items():\n",
    "        if corpus not in columns:\n",
    "            columns.append(corpus)\n",
    "        process_data.append(documents['average']['diff'])\n",
    "    aggregated_data.append(process_data)\n",
    "    process_data = [\"Tokens\"]\n",
    "    for corpus, documents in process.items():\n",
    "        process_data.append(documents['average']['diff_tokens'])\n",
    "    aggregated_data.append(process_data)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(aggregated_data, columns=columns)"
   ],
   "id": "6290ffccf7a4c38c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Process type  PLOS_1000  eLife_984  biorxiv-10k-test-2000  PMC_sample_1943\n",
       "0     standard        0.0   0.000000               0.000000         0.000000\n",
       "1       Tokens        0.0   0.094608               0.075962         0.104016"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process type</th>\n",
       "      <th>PLOS_1000</th>\n",
       "      <th>eLife_984</th>\n",
       "      <th>biorxiv-10k-test-2000</th>\n",
       "      <th>PMC_sample_1943</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>standard</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tokens</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094608</td>\n",
       "      <td>0.075962</td>\n",
       "      <td>0.104016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analysis specific documents",
   "id": "201380166577b233"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:52:28.693642Z",
     "start_time": "2025-05-06T09:52:28.681695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for process_type, process in documents_output.items():\n",
    "    print(process_type)\n",
    "    for corpus, documents in process.items():\n",
    "        print(f\"\\t{corpus}\")\n",
    "        sorted_by_diff = sorted(\n",
    "            documents['processed'].items(),\n",
    "            key=lambda x: x[1]['stats']['diff_chars_no_spaces']\n",
    "        )\n",
    "\n",
    "        sorted_by_diff_tokens = sorted(\n",
    "            documents['processed'].items(),\n",
    "            key=lambda x: x[1]['stats']['diff_tokens']\n",
    "        )\n",
    "\n",
    "        output_neg = [f\"\\n\\t\\t\\t -{item[0]}: {item[1]['stats']['diff_chars_no_spaces']}\" for item in sorted_by_diff[:2]]\n",
    "        print(\"\".join(output_neg))\n",
    "        output_pos = [f\"\\n\\t\\t\\t -{item[0]}: {item[1]['stats']['diff_chars_no_spaces']}\" for item in sorted_by_diff[-2:]]\n",
    "        print(\"\".join(output_pos))\n",
    "        # print(f\"Files to check:\\n {[item[0] for item in sorted_by_diff_tokens[:2]]}\")\n"
   ],
   "id": "f4da94821bc2d8e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard\n",
      "\tPLOS_1000\n",
      "\n",
      "\t\t\t -pone.0278552/pone.0278552: 0\n",
      "\t\t\t -pone.0278760/pone.0278760: 0\n",
      "\n",
      "\t\t\t -pone.0278529/pone.0278529: 0\n",
      "\t\t\t -pone.0278971/pone.0278971: 0\n",
      "\teLife_984\n",
      "\n",
      "\t\t\t -13841/elife-13841-v2: 0\n",
      "\t\t\t -20851/elife-20851-v1: 0\n",
      "\n",
      "\t\t\t -39393/elife-39393-v3: 91\n",
      "\t\t\t -29953/elife-29953-v1: 96\n",
      "\tbiorxiv-10k-test-2000\n",
      "\n",
      "\t\t\t -394296v1/394296v1: -6\n",
      "\t\t\t -468470v1/468470v1: -1\n",
      "\n",
      "\t\t\t -055756v1/055756v1: 551\n",
      "\t\t\t -157206v1/157206v1: 746\n",
      "\tPMC_sample_1943\n",
      "\n",
      "\t\t\t -Mov_Disord_2011_Mar_2_26(4)_653-658/mds0026-0653: 0\n",
      "\t\t\t -Brain_Cell_Biol_2008_Aug_11_36(1-4)_101-118/11068_2008_Article_9031: 0\n",
      "\n",
      "\t\t\t -Open_Cardiovasc_Med_J_2011_May_2_5_99-102/TOCMJ-5-99: 85\n",
      "\t\t\t -Chem_Rev_2010_Aug_11_110(8)_4820-4838/cr900377t: 390\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:52:28.825997Z",
     "start_time": "2025-05-06T09:52:28.821586Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a34716d113f49f99",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
